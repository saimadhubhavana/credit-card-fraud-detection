{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46e11442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb97c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c23d46f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "#get information about dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c4ef2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Fraud    284315\n",
      "Fraud           492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#predict the initialized record to classify the data as fraud or not\n",
    "class_names = {0:'Not Fraud', 1:'Fraud'}\n",
    "print(df.Class.value_counts().rename(index = class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f5826ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bfc36a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
      "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
      "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
      "      dtype='object')\n",
      "Index(['Class'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Dividing the predicted and actual columns\n",
    "feature_names = df.iloc[:, 1:30].columns\n",
    "target = df.iloc[:1, 30: ].columns\n",
    "print(feature_names)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "432116a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing the data into different the data frames accordingly\n",
    "data_features = df[feature_names]\n",
    "data_target = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7027075f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_train is: 199364\n",
      "Length of X_test is: 85443\n",
      "Length of y_train is: 199364\n",
      "Length of y_test is: 85443\n"
     ]
    }
   ],
   "source": [
    "#splitting the data into training and testing data as 70:30\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_features, data_target, train_size=0.70, test_size=0.30, random_state=1)\n",
    "print(\"Length of X_train is: {X_train}\".format(X_train = len(X_train)))\n",
    "print(\"Length of X_test is: {X_test}\".format(X_test = len(X_test)))\n",
    "print(\"Length of y_train is: {y_train}\".format(y_train = len(y_train)))\n",
    "print(\"Length of y_test is: {y_test}\".format(y_test = len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87206825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7671472f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhava\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating Logistic Regression Model and feeding the data to the model to train itself\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3107481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating and storing the predicted values\n",
    "pred1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fff11fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the confusion matrix to evaluate the models performance\n",
    "class_names = ['not_fraud', 'fraud']\n",
    "matrix = confusion_matrix(y_test, pred1)\n",
    "# Create pandas dataframe\n",
    "dataframe = pd.DataFrame(matrix, index=class_names, columns=class_names)\n",
    "# Create heatmap\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\", fmt = 'g')\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f2431b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity/Recall for Logistic Regression Model 1 : 0.56\n",
      "F1 Score for Logistic Regression Model 1 : 0.68\n",
      "Accuracy Score for Logistic Regression Model 1 :0.9991573329588147\n"
     ]
    }
   ],
   "source": [
    "#printing accuracy, F1 score and sensitivity/recall of the model\n",
    "from sklearn.metrics import f1_score, recall_score , accuracy_score\n",
    "f1_score = round(f1_score(y_test, pred1), 2)\n",
    "recall_score = round(recall_score(y_test, pred1), 2)\n",
    "print(\"Sensitivity/Recall for Logistic Regression Model 1 : {recall_score}\".format(recall_score = recall_score))\n",
    "print(\"F1 Score for Logistic Regression Model 1 : {f1_score}\".format(f1_score = f1_score))\n",
    "print(\"Accuracy Score for Logistic Regression Model 1 :\"+ str(accuracy_score(y_test,pred1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d60b855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating Decision Tree Regressor Model and feeding the data to the model to train itself\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model2=DecisionTreeRegressor()\n",
    "model2.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3e0bc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating and storing the predicted values\n",
    "pred2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa1fd7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the confusion matrix to evaluate the models performance\n",
    "class_names = ['not_fraud', 'fraud']\n",
    "matrix = confusion_matrix(y_test, pred2)\n",
    "# Create pandas dataframe\n",
    "dataframe = pd.DataFrame(matrix, index=class_names, columns=class_names)\n",
    "# Create heatmap\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\", fmt = 'g')\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4cb487f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity/Recall for Decision Tree Regression Model 2 : 0.73\n",
      "F1 Score for Decision Tree Regression Model 2 : 0.73\n",
      "Accuracy Score for Decision Tree Regression Model 2 :0.9991573329588147\n"
     ]
    }
   ],
   "source": [
    "#printing accuracy, F1 score and sensitivity/recall of the model\n",
    "from sklearn.metrics import f1_score, recall_score , accuracy_score\n",
    "f1_score = round(f1_score(y_test, pred2), 2)\n",
    "recall_score = round(recall_score(y_test, pred2), 2)\n",
    "print(\"Sensitivity/Recall for Decision Tree Regression Model 2 : {recall_score}\".format(recall_score = recall_score))\n",
    "print(\"F1 Score for Decision Tree Regression Model 2 : {f1_score}\".format(f1_score = f1_score))\n",
    "print(\"Accuracy Score for Decision Tree Regression Model 2 :\"+ str(accuracy_score(y_test,pred2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "197c15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN Model\n",
    "# Libraries that we will need to create ANN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c7f56bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building our Neural Network\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(40 , input_dim = 29 , activation = 'relu'))\n",
    "model3.add(Dense(30 , input_dim = 40 , activation = 'relu'))\n",
    "model3.add(Dense(20 , input_dim = 30 , activation = 'relu'))\n",
    "model3.add(Dense(10 , input_dim = 20 , activation = 'relu'))\n",
    "model3.add(Dense(6 , input_dim = 10 , activation = 'relu'))\n",
    "model3.add(Dense(4 , input_dim = 6 , activation = 'relu'))\n",
    "model3.add(Dense(1, input_dim = 4 , activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b325db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying our loss and optimizer\n",
    "model3.compile(loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d724875f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "399/399 [==============================] - 3s 5ms/step - loss: 0.0384 - accuracy: 0.9982\n",
      "Epoch 2/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0062 - accuracy: 0.9982\n",
      "Epoch 3/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "Epoch 4/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0044 - accuracy: 0.9982\n",
      "Epoch 5/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0042 - accuracy: 0.9982\n",
      "Epoch 6/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 7/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0039 - accuracy: 0.9993\n",
      "Epoch 8/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0038 - accuracy: 0.9994\n",
      "Epoch 9/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0035 - accuracy: 0.9994\n",
      "Epoch 10/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0034 - accuracy: 0.9994\n",
      "Epoch 11/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0037 - accuracy: 0.9994\n",
      "Epoch 12/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 13/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 14/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0031 - accuracy: 0.9994\n",
      "Epoch 15/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0031 - accuracy: 0.9994\n",
      "Epoch 16/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0029 - accuracy: 0.9995\n",
      "Epoch 17/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 18/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 19/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0028 - accuracy: 0.9995\n",
      "Epoch 20/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 21/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0025 - accuracy: 0.9995\n",
      "Epoch 22/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0025 - accuracy: 0.9995\n",
      "Epoch 23/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 24/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0025 - accuracy: 0.9995\n",
      "Epoch 25/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 26/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 27/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 28/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 29/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 30/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0020 - accuracy: 0.9996\n",
      "Epoch 31/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0019 - accuracy: 0.9996\n",
      "Epoch 32/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0020 - accuracy: 0.9996\n",
      "Epoch 33/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0020 - accuracy: 0.9996\n",
      "Epoch 34/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 35/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0019 - accuracy: 0.9996\n",
      "Epoch 36/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 37/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 38/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0022 - accuracy: 0.9996\n",
      "Epoch 39/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 40/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 41/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 42/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 43/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 44/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 45/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 46/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 47/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 48/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 49/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 50/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 51/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 52/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 53/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 54/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 55/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 56/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 57/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 58/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 59/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 60/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 61/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 62/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 63/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 64/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 65/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 66/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 67/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 68/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 69/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 70/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 71/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 72/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 73/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 74/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 75/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 76/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 77/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 78/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 79/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 80/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 82/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 83/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 84/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 85/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 86/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 87/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 88/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 89/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 90/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 91/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 92/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 93/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 94/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 95/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 96/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 97/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 98/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 99/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 100/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 101/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 102/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 103/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 104/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 105/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 106/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 107/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 108/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 109/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 110/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 111/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 112/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 113/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 114/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 115/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 116/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 117/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 118/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 119/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 120/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 121/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 122/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 123/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 124/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 125/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 126/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 127/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 128/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 129/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 130/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 131/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 132/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 133/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 134/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 135/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 136/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 137/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 138/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 139/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 140/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 141/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 142/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 143/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 144/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 145/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 146/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 147/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 148/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 149/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 150/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 151/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 152/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 153/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 154/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 155/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 156/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 157/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 158/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 159/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 161/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 162/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 163/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 164/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 165/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 166/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 167/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 168/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 169/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 170/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 171/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 172/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 173/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 174/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 175/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 176/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 177/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 178/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 179/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 180/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 181/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 182/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 183/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 184/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 185/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 186/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 187/200\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 188/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 189/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 190/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 191/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 192/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 193/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 194/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 195/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 196/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 197/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 198/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 199/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 200/200\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b8de5629a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting our data to ANN\n",
    "model3.fit( X_train , y_train , epochs = 200 , batch_size = 500 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4205fc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2671/2671 [==============================] - 7s 2ms/step - loss: 0.0048 - accuracy: 0.9994\n"
     ]
    }
   ],
   "source": [
    "# Getting the results\n",
    "model3.evaluate(X_test,y_test)\n",
    "pred3 = np.argmax(model3.predict(X_test), axis= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9c5f8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity/Recall for ANN Model 3 : 0.0\n",
      "F1 Score for ANN Model 3 : 0.0\n",
      "Accuracy Score for ANN Model 3 :0.9984199992977775\n"
     ]
    }
   ],
   "source": [
    "#printing accuracy, F1 score and sensitivity/recall of the model\n",
    "from sklearn.metrics import f1_score, recall_score , accuracy_score\n",
    "f1_score = round(f1_score(y_test, pred3), 2)\n",
    "recall_score = round(recall_score(y_test, pred3), 2)\n",
    "print(\"Sensitivity/Recall for ANN Model 3 : {recall_score}\".format(recall_score = recall_score))\n",
    "print(\"F1 Score for ANN Model 3 : {f1_score}\".format(f1_score = f1_score))\n",
    "print(\"Accuracy Score for ANN Model 3 :\"+ str(accuracy_score(y_test,pred3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2798d913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting Model\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "871120d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhava\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.3231           22.68m\n",
      "         2        1111.4913           22.50m\n",
      "         3        1111.4398           22.23m\n",
      "         4        1111.4398           22.13m\n",
      "         5        1111.4398           22.06m\n",
      "         6        1111.4398           21.99m\n",
      "         7        1111.4398           21.91m\n",
      "         8        1111.4398           21.78m\n",
      "         9        1111.4398           21.66m\n",
      "        10        1111.4398           21.55m\n",
      "        20        1111.4398           20.47m\n",
      "        30        1111.4398           19.33m\n",
      "        40        1111.4398           18.20m\n",
      "        50        1111.4398           17.07m\n",
      "        60        1111.4398           15.93m\n",
      "        70        1111.4398           14.79m\n",
      "        80        1111.4398           13.65m\n",
      "        90        1111.4398           12.55m\n",
      "       100        1111.4398           11.40m\n",
      "       200        1111.4398            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=1, n_estimators=200, random_state=0,\n",
       "                           verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating Gradient Boosting Model and feeding the data to the model to train and test itself\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model4 = GradientBoostingClassifier(n_estimators=200, max_depth=3, learning_rate=1, random_state=0, verbose = 1)\n",
    "model4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9626672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating and storing the predicted values\n",
    "pred4 = model4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18cd66c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the confusion matrix to evaluate the models performance\n",
    "class_names = ['not_fraud', 'fraud']\n",
    "matrix = confusion_matrix(y_test, pred4)\n",
    "# Create pandas dataframe\n",
    "dataframe = pd.DataFrame(matrix, index=class_names, columns=class_names)\n",
    "# Create heatmap\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\", fmt = 'g')\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf2956e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity/Recall for Gradient Boosting  Model 4 : 0.67\n",
      "F1 Score for Gradient Boosting  Model 4 : 0.63\n",
      "Accuracy Score for Gradient Boosting  Model 4 :0.9987828142738434\n"
     ]
    }
   ],
   "source": [
    "#printing accuracy, F1 score and sensitivity/recall of the model\n",
    "from sklearn.metrics import f1_score, recall_score , accuracy_score\n",
    "f1_score = round(f1_score(y_test, pred4), 2)\n",
    "recall_score = round(recall_score(y_test, pred4), 2)\n",
    "print(\"Sensitivity/Recall for Gradient Boosting  Model 4 : {recall_score}\".format(recall_score = recall_score))\n",
    "print(\"F1 Score for Gradient Boosting  Model 4 : {f1_score}\".format(f1_score = f1_score))\n",
    "print(\"Accuracy Score for Gradient Boosting  Model 4 :\"+ str(accuracy_score(y_test,pred4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b541593a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
